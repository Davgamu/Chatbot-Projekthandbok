
import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import RetrievalQA
from pypdf import PdfReader
import os

st.set_page_config(page_title="Projekthandbokens RAG-Chatbot", layout="wide")
st.title("üí¨ Projekthandbokens RAG-Chatbot")
st.markdown("St√§ll fr√•gor om G√∂teborg Energis projekthandbok (PDF) i ett chattformat.")

# API-nyckel
api_key = st.text_input("üîë Ange din OpenAI API-nyckel", type="password")
if not api_key:
    st.warning("V√§nligen ange din API-nyckel f√∂r att komma ig√•ng.")
    st.stop()
os.environ["OPENAI_API_KEY"] = api_key

# Session state f√∂r chatt
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Ladda PDF
pdf_file = st.file_uploader("üìÑ Ladda upp PDF-filen", type="pdf")
if pdf_file:
    reader = PdfReader(pdf_file)
    text = ""
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"

    # Chunkning
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = splitter.split_text(text)

    # Embedding + FAISS
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_texts(texts, embedding=embeddings)

    # Prompt med sekretess
    system_prompt = (
        "Du √§r en hj√§lpsam assistent f√∂r G√∂teborg Energis projekthandbok. "
        "Du f√•r inte ange, gissa eller f√∂resl√• personlig information om n√•gon person. "
        "Om fr√•gan g√§ller individer, svara ist√§llet: 'Jag kan inte ge personlig information.'"
    )
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(system_prompt),
        HumanMessagePromptTemplate.from_template("Kontekst:\n{context}\n\nFr√•ga: {question}")
    ])

    retriever = db.as_retriever()
    llm = ChatOpenAI(model_name="gpt-3.5-turbo")
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        chain_type_kwargs={"prompt": prompt},
        input_key="question"
    )

    # Anv√§ndarens fr√•ga
    fr√•ga = st.chat_input("‚ùì St√§ll din fr√•ga h√§r")
    if fr√•ga:
        st.session_state.chat_history.append(("user", fr√•ga))
        svar = qa.invoke({"question": fr√•ga})
        st.session_state.chat_history.append(("ai", svar))

    # Visa chatthistorik
    for roll, meddelande in st.session_state.chat_history:
        if roll == "user":
            with st.chat_message("üë§ Du"):
                st.markdown(meddelande)
        else:
            with st.chat_message("ü§ñ Assistent"):
                st.markdown(meddelande)
